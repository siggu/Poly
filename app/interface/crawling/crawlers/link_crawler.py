import sys
import os

# ê³µí†µ ëª¨ë“ˆ import
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
import config
import utils
from base.base_crawler import BaseCrawler


def main():
    """
    ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜
    """
    # 1. ì‚¬ìš©ì ì…ë ¥
    start_url = input("ë¶„ì„í•  ì›¹ì‚¬ì´íŠ¸ URLì„ ì…ë ¥í•˜ì„¸ìš”: ")

    # 2. â­ ë™ì  base_url ìƒì„±
    try:
        base_url = utils.get_base_url(start_url)
        print(f"--- 0ë‹¨ê³„: ê¸°ë³¸ URLì„ '{base_url}' (ìœ¼)ë¡œ ì„¤ì •í•©ë‹ˆë‹¤ ---")
    except ValueError as e:
        print(f"[ì˜¤ë¥˜] {e}")
        return

    # BaseCrawler ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    crawler = BaseCrawler()

    print("\n--- 1ë‹¨ê³„: ë©”ì¸ ì¹´í…Œê³ ë¦¬ ë§í¬ ìˆ˜ì§‘ ì‹œì‘ ---")

    # 3. ì‹œì‘ í˜ì´ì§€ íŒŒì‹±
    soup = crawler.fetch_page(start_url)
    if not soup:
        print("ì‹œì‘ í˜ì´ì§€ì— ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 4. â­ ì¼ì¹˜í•˜ëŠ” 'ê·œì¹™' ì°¾ê¸°
    main_links = []
    active_rule = None

    for rule in config.CRAWL_RULES:
        print(f"  [ì‹œë„] ê·œì¹™ '{rule['name']}' (ì„ íƒì: {rule['main_selector']})")
        main_links = soup.select(rule["main_selector"])
        if main_links:
            print(f"  [ì„±ê³µ] ì´ ê·œì¹™ìœ¼ë¡œ {len(main_links)}ê°œì˜ ë§í¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            active_rule = rule  # ì‚¬ìš©ëœ ê·œì¹™ì„ ì €ì¥
            break

    if not active_rule:
        print("\n[ì˜¤ë¥˜] 1ë‹¨ê³„ ë©”ë‰´ ë§í¬ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("CRAWL_RULESì— ì •ì˜ëœ 'main_selector' ì¤‘ ì¼ì¹˜í•˜ëŠ” ê²ƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 5. 1ë‹¨ê³„ ë©”ë‰´ ë§í¬ ì²˜ë¦¬
    main_categories = []
    for link in main_links:
        category_name = link.get_text().strip()
        relative_href = link.get("href")

        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        absolute_url = utils.make_absolute_url(relative_href, base_url)

        main_categories.append({"name": category_name, "url": absolute_url})
        # print(f"  [ìˆ˜ì§‘] {category_name} ({absolute_url})") # 1ë‹¨ê³„ ë¡œê·¸ëŠ” ì„±ê³µ ë¡œê·¸ë¡œ ëŒ€ì²´

    print(
        f"\n--- 2ë‹¨ê³„: ì´ {len(main_categories)}ê°œì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ìˆœíšŒí•˜ë©° í•˜ìœ„ ë©”ë‰´ ìˆ˜ì§‘ ---"
    )

    # 6. ìˆ˜ì§‘ëœ 1ë‹¨ê³„ ë©”ë‰´ë¥¼ ìˆœíšŒí•˜ë©° ê° í˜ì´ì§€ì˜ í•˜ìœ„ ë©”ë‰´ ìˆ˜ì§‘
    all_menus_data = {}

    for category in main_categories:
        print(f"\n[ë°©ë¬¸ ì¤‘...] {category['name']} ({category['url']})")

        # ì™¸ë¶€ ë§í¬(base_urlë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ë§í¬)ëŠ” ê±´ë„ˆë›°ê¸°
        if not category["url"].startswith(base_url):
            print("  [ì•Œë¦¼] ì™¸ë¶€ ì‚¬ì´íŠ¸ì´ë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.")
            all_menus_data[category["name"]] = []
            continue

        category_soup = crawler.fetch_page(category["url"])
        if not category_soup:
            continue

        sub_menu_list = []

        # â­ í™œì„±í™”ëœ ê·œì¹™(active_rule)ì˜ 'sub_selector'ë¥¼ ì‚¬ìš©
        found_sub_links = False

        for finder_selector in active_rule["policy_finders"]:
            sub_links = category_soup.select(finder_selector)

            if sub_links:
                # í•˜ìœ„ ë©”ë‰´ê°€ ìˆìœ¼ë©´(Case 1: LNB ë˜ëŠ” Tab), í•˜ìœ„ ë©”ë‰´ë“¤ì„ ìˆ˜ì§‘
                print(
                    f"  [ì•Œë¦¼] (ê·œì¹™: {finder_selector})ì—ì„œ í•˜ìœ„ ë©”ë‰´ {len(sub_links)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                )
                found_sub_links = True

                for sub_link in sub_links:
                    sub_name = sub_link.get_text().strip()
                    sub_href = utils.make_absolute_url(sub_link.get("href"), base_url)
                    sub_menu_list.append({"name": sub_name, "url": sub_href})

                break  # í•˜ìœ„ ë§í¬ë¥¼ ì°¾ì•˜ìœ¼ë¯€ë¡œ ë‹¤ìŒ ê·œì¹™(finder)ì€ í™•ì¸í•  í•„ìš” ì—†ìŒ

        if not found_sub_links:
            # í•˜ìœ„ ë©”ë‰´ê°€ ì—†ìœ¼ë©´(Case 2), ì¹´í…Œê³ ë¦¬ ìì²´ë¥¼ ë‹¨ì¼ í•­ëª©ìœ¼ë¡œ ê°„ì£¼
            print("  [ì•Œë¦¼] í•˜ìœ„ ë©”ë‰´ê°€ ì—†ìŠµë‹ˆë‹¤. ì¹´í…Œê³ ë¦¬ ìì²´ë¥¼ í•­ëª©ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            sub_menu_list.append({"name": category["name"], "url": category["url"]})
        all_menus_data[category["name"]] = sub_menu_list

    # 7. ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n\n--- ğŸŒŸ ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼ ğŸŒŸ ---")
    for main_name, sub_menus in all_menus_data.items():
        print(f"\nâ–  {main_name}")
        if sub_menus:
            for sub in sub_menus:
                print(f"  - {sub['name']} ({sub['url']})")
        else:
            print("  (í•˜ìœ„ ë©”ë‰´ ì—†ìŒ ë˜ëŠ” ì™¸ë¶€ ë§í¬)")


# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    main()
